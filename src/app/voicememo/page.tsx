'use client';

/* eslint-disable @typescript-eslint/no-explicit-any */

import { useState, useRef, useEffect } from 'react';
import Header from '@/components/Header';
import { getUserId, getShortUserId } from '@/utils/userUtils';

interface MemoData {
  id: number;
  user_id: string;
  content: string;
  created_at: string;
  updated_at: string;
}

export default function VoiceMemoPage() {
  const [isRecording, setIsRecording] = useState(false);
  const [memos, setMemos] = useState<MemoData[]>([]);
  const [currentTranscript, setCurrentTranscript] = useState('');
  const [isLoadingMemos, setIsLoadingMemos] = useState(true);
  const [userId, setUserId] = useState<string>('');
  const [debugInfo, setDebugInfo] = useState<{
    userAgent: string;
    speechSupport: boolean;
    mediaDevicesSupport: boolean;
    isMobile: boolean;
    useServerSTT: boolean;
  } | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recognitionRef = useRef<unknown>(null);
  const audioChunksRef = useRef<BlobPart[]>([]);
  const chunkTimerRef = useRef<NodeJS.Timeout | null>(null);

  // ë©”ëª¨ ëª©ë¡ ì¡°íšŒ í•¨ìˆ˜
  const fetchMemos = async (userIdParam: string) => {
    try {
      const response = await fetch(`/api/memo?userId=${encodeURIComponent(userIdParam)}`);
      const result = await response.json();

      if (result.success) {
        setMemos(result.data);
      } else {
        console.error('Failed to fetch memos:', result.message);
      }
    } catch (error) {
      console.error('Error fetching memos:', error);
    } finally {
      setIsLoadingMemos(false);
    }
  };

  // ë©”ëª¨ ì €ì¥ í•¨ìˆ˜
  const saveMemo = async (content: string) => {
    if (!userId || !content.trim()) return;

    try {
      const response = await fetch('/api/memo', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          userId: userId,
          content: content.trim()
        }),
      });

      const result = await response.json();

      if (result.success) {
        console.log('ë©”ëª¨ ì €ì¥ ì„±ê³µ:', result.data);
        // ë©”ëª¨ ëª©ë¡ ìƒˆë¡œê³ ì¹¨
        await fetchMemos(userId);
      } else {
        console.error('Failed to save memo:', result.message);
      }
    } catch (error) {
      console.error('Error saving memo:', error);
    }
  };

  // ë©”ëª¨ ì‚­ì œ í•¨ìˆ˜
  const deleteMemo = async (memoId: number) => {
    if (!userId) return;

    try {
      const response = await fetch(`/api/memo?id=${memoId}&userId=${encodeURIComponent(userId)}`, {
        method: 'DELETE',
      });

      const result = await response.json();

      if (result.success) {
        console.log('ë©”ëª¨ ì‚­ì œ ì„±ê³µ');
        // ë©”ëª¨ ëª©ë¡ ìƒˆë¡œê³ ì¹¨
        await fetchMemos(userId);
      } else {
        console.error('Failed to delete memo:', result.message);
      }
    } catch (error) {
      console.error('Error deleting memo:', error);
    }
  };

  // Initialize user ID and fetch data on component mount
  useEffect(() => {
    // ì‚¬ìš©ì ID ì´ˆê¸°í™”
    const initUserId = getUserId();
    setUserId(initUserId);
    console.log('ì‚¬ìš©ì ID ì´ˆê¸°í™”:', initUserId);

    // ë””ë²„ê·¸ ì •ë³´ ì„¤ì •
    const isMobile = /Android|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
    const speechSupport = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
    const mediaDevicesSupport = 'mediaDevices' in navigator && 'getUserMedia' in navigator.mediaDevices;

    // ëª¨ë°”ì¼ í™˜ê²½ì—ì„œëŠ” ì„œë²„ STT ì‚¬ìš©, ë°ìŠ¤í¬í†±ì—ì„œëŠ” Web Speech API ì‚¬ìš©
    const useServerSTT = isMobile || !speechSupport;

    setDebugInfo({
      userAgent: navigator.userAgent,
      speechSupport,
      mediaDevicesSupport,
      isMobile,
      useServerSTT
    });

    console.log('ğŸ” ë””ë²„ê·¸ ì •ë³´:', {
      isMobile,
      speechSupport,
      mediaDevicesSupport,
      userAgent: navigator.userAgent
    });

    // ë©”ëª¨ ëª©ë¡ ì¡°íšŒ
    fetchMemos(initUserId);
  }, []);

  // ì„œë²„ STTë¡œ ì˜¤ë””ì˜¤ ì²­í¬ ì—…ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¸ì‹
  const uploadAudioChunk = async (audioBlob: Blob) => {
    try {
      console.log('ğŸ“¤ ì˜¤ë””ì˜¤ ì²­í¬ ì—…ë¡œë“œ ì‹œì‘:', { size: audioBlob.size, type: audioBlob.type });

      const formData = new FormData();
      formData.append('audio', audioBlob, `chunk.${audioBlob.type.includes('webm') ? 'webm' : 'mp4'}`);

      const response = await fetch('/api/stt', {
        method: 'POST',
        body: formData
      });

      if (!response.ok) {
        throw new Error(`STT API ì˜¤ë¥˜: ${response.statusText}`);
      }

      const result = await response.json();
      console.log('ğŸ“ STT ê²°ê³¼ ìˆ˜ì‹ :', result);

      if (result.text) {
        // ëª¨ë°”ì¼ ëª¨ë“œì—ì„œëŠ” ì „ì²´ í…ìŠ¤íŠ¸ë¡œ êµì²´ (ëˆ„ì í•˜ì§€ ì•ŠìŒ)
        setCurrentTranscript(result.text.trim());
        console.log('ğŸ“„ í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ:', result.text.trim());
      }

    } catch (error) {
      console.error('âŒ STT ì—…ë¡œë“œ ì˜¤ë¥˜:', error);
    }
  };

  const startRecording = async () => {
    try {
      console.log('ğŸ¤ ìŒì„± ë…¹ìŒ ì‹œì‘ ì‹œë„...');

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      console.log('âœ… ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íšë“ ì„±ê³µ');

      // MediaRecorder mimeType í˜¸í™˜ì„± ì²˜ë¦¬
      let mimeType = 'audio/webm;codecs=opus';
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'audio/webm';
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = 'audio/mp4'; // iOS Safari ëŒ€ë¹„
        }
      }
      console.log('ğŸ“¼ ì‚¬ìš©í•  MIME íƒ€ì…:', mimeType);

      const mediaRecorder = new MediaRecorder(stream, { mimeType });
      mediaRecorderRef.current = mediaRecorder;

      // ì˜¤ë””ì˜¤ ì²­í¬ ì´ˆê¸°í™”
      audioChunksRef.current = [];

      // MediaRecorder ì´ë²¤íŠ¸ ì„¤ì •
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          console.log('ğŸ“¦ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì§‘:', event.data.size, 'bytes');
        }
      };

      const isMobile = /Android|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
      const speechSupport = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
      const useServerSTT = isMobile || !speechSupport;

      if (useServerSTT) {
        console.log('ğŸ”„ ì„œë²„ STT ëª¨ë“œ ì‹œì‘ (ëª¨ë°”ì¼ ë˜ëŠ” Web Speech ë¯¸ì§€ì›)');
        console.log('ğŸ“± ëª¨ë°”ì¼ ëª¨ë“œ: ë…¹ìŒ ì¢…ë£Œ í›„ ì¼ê´„ ì „ì†¡ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë³€í™˜');

      } else {
        console.log('ğŸ—£ï¸ ë°ìŠ¤í¬í†± Web Speech API ëª¨ë“œ ì‹œì‘');

        // ë°ìŠ¤í¬í†±: Web Speech API ì‚¬ìš©
        const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
        const recognition = new SpeechRecognition();

        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'ko-KR';
        recognition.maxAlternatives = 1;

        recognition.onstart = () => {
          console.log('ğŸ¤ Web Speech Recognition ì‹œì‘ë¨');
        };

        recognition.onresult = (event: any) => {
          let transcript = '';
          let finalTranscript = '';

          for (let i = event.resultIndex; i < event.results.length; i++) {
            const result = event.results[i];
            if (result.isFinal) {
              finalTranscript += result[0].transcript;
            } else {
              transcript += result[0].transcript;
            }
          }

          const currentText = finalTranscript || transcript;
          console.log('ğŸ“ Web Speech ì¸ì‹ í…ìŠ¤íŠ¸:', currentText);
          setCurrentTranscript(currentText);
        };

        recognition.onerror = (event: any) => {
          console.error('âŒ Web Speech Recognition ì˜¤ë¥˜:', event.error);
          if (event.error === 'not-allowed') {
            alert('ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
          }
        };

        recognition.onend = () => {
          console.log('ğŸ›‘ Web Speech Recognition ì¢…ë£Œë¨');
        };

        try {
          recognition.start();
          recognitionRef.current = recognition;
          console.log('ğŸ¤ Web Speech Recognition ì‹œì‘ ëª…ë ¹ ì‹¤í–‰');
        } catch (speechError) {
          console.error('âŒ Web Speech Recognition ì‹œì‘ ì‹¤íŒ¨:', speechError);
        }
      }

      // MediaRecorder ì‹œì‘ (1ì´ˆ ê°„ê²©ìœ¼ë¡œ dataavailable ì´ë²¤íŠ¸ ë°œìƒ)
      mediaRecorder.start(1000);
      setIsRecording(true);
      setCurrentTranscript('');
      console.log('âœ… ë…¹ìŒ ì‹œì‘ ì™„ë£Œ - ëª¨ë“œ:', useServerSTT ? 'ì„œë²„ STT (ë…¹ìŒ ì¢…ë£Œ í›„ ì¼ê´„ ì²˜ë¦¬)' : 'Web Speech API (ì‹¤ì‹œê°„)');

    } catch (error) {
      console.error('âŒ ë…¹ìŒ ì‹œì‘ ì¤‘ ì˜¤ë¥˜:', error);
      alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  };

  const stopRecording = async () => {
    console.log('ğŸ›‘ ìŒì„± ë…¹ìŒ ì¤‘ì§€ ì‹œì‘...');

    // ì²­í¬ ì—…ë¡œë“œ íƒ€ì´ë¨¸ ì¤‘ì§€ (ì‹¤ì œë¡œëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    if (chunkTimerRef.current) {
      clearInterval(chunkTimerRef.current);
      chunkTimerRef.current = null;
      console.log('â° ì²­í¬ ì—…ë¡œë“œ íƒ€ì´ë¨¸ ì¤‘ì§€');
    }

    // MediaRecorder ì¤‘ì§€
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      console.log('âœ… MediaRecorder ì¤‘ì§€ ì™„ë£Œ');
    }

    // Web Speech Recognition ì¤‘ì§€ (ë°ìŠ¤í¬í†±ì—ì„œë§Œ)
    if (recognitionRef.current) {
      (recognitionRef.current as any).stop();
      console.log('âœ… Web Speech Recognition ì¤‘ì§€ ì™„ë£Œ');
    }

    setIsRecording(false);

    // ëª¨ë°”ì¼/ì„œë²„ STT ëª¨ë“œ: ì „ì²´ ë…¹ìŒ íŒŒì¼ì„ í•œë²ˆì— ì²˜ë¦¬
    const isMobile = /Android|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
    const speechSupport = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
    const useServerSTT = isMobile || !speechSupport;

    if (useServerSTT && audioChunksRef.current.length > 0) {
      console.log('ğŸ“± ëª¨ë°”ì¼ ëª¨ë“œ: ì „ì²´ ë…¹ìŒ íŒŒì¼ ì¼ê´„ ì²˜ë¦¬ ì‹œì‘...');
      setCurrentTranscript('ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...');

      const chunks = audioChunksRef.current.splice(0);
      const mimeType = mediaRecorderRef.current?.mimeType || 'audio/webm';
      const audioBlob = new Blob(chunks, { type: mimeType });

      console.log('ğŸ“¤ ì „ì²´ ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ:', {
        size: audioBlob.size,
        type: audioBlob.type,
        duration: 'ì „ì²´ ë…¹ìŒ'
      });

      if (audioBlob.size > 0) {
        await uploadAudioChunk(audioBlob);
      }

      // í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ ëŒ€ê¸°
      setTimeout(async () => {
        console.log('ğŸ“ ìµœì¢… ì¸ì‹ëœ í…ìŠ¤íŠ¸:', currentTranscript);

        // ìŒì„± ì¸ì‹ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        if (currentTranscript.trim() && currentTranscript !== 'ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...') {
          console.log('ğŸ’¾ ë©”ëª¨ ì €ì¥ ì‹œì‘...');
          await saveMemo(currentTranscript.trim());
          console.log('âœ… ë©”ëª¨ ì €ì¥ ì™„ë£Œ');
        } else {
          console.log('âš ï¸ ì €ì¥í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤');
        }

        setCurrentTranscript('');
      }, 2000); // 2ì´ˆ ëŒ€ê¸° í›„ ì €ì¥ (ì„œë²„ ì²˜ë¦¬ ì‹œê°„ ê³ ë ¤)

    } else if (!useServerSTT) {
      // ë°ìŠ¤í¬í†± Web Speech API ëª¨ë“œ
      setTimeout(async () => {
        console.log('ğŸ“ ìµœì¢… ì¸ì‹ëœ í…ìŠ¤íŠ¸:', currentTranscript);

        // ìŒì„± ì¸ì‹ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        if (currentTranscript.trim()) {
          console.log('ğŸ’¾ ë©”ëª¨ ì €ì¥ ì‹œì‘...');
          await saveMemo(currentTranscript.trim());
          console.log('âœ… ë©”ëª¨ ì €ì¥ ì™„ë£Œ');
        } else {
          console.log('âš ï¸ ì €ì¥í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤');
        }

        setCurrentTranscript('');
      }, 1000); // 1ì´ˆ ëŒ€ê¸° í›„ ì €ì¥
    }
  };

  return (
    <div className="min-h-screen bg-gray-950 text-white">
      <Header title="Voice Memo" />

      <div className="pt-20 px-4 max-w-4xl mx-auto">
        <div className="text-center mb-8">
          <h1 className="text-3xl font-bold mb-4">ìŒì„± ë©”ëª¨</h1>
          <p className="text-gray-400">ë²„íŠ¼ì„ ëˆŒëŸ¬ ìŒì„±ì„ ë…¹ìŒí•˜ê³  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì„¸ìš”</p>

          {/* User ID Display */}
          {userId && (
            <div className="mt-4 inline-flex items-center gap-2 px-3 py-1 bg-gray-800 rounded-full">
              <div className="w-2 h-2 bg-green-500 rounded-full"></div>
              <span className="text-xs text-gray-300">
                ì‚¬ìš©ì ID: {getShortUserId(userId)}
              </span>
            </div>
          )}
        </div>

        {/* Debug Information for Mobile Testing */}
        {debugInfo && (
          <div className="bg-gray-800 rounded-lg p-4 mb-6">
            <h3 className="text-sm font-semibold mb-2 text-yellow-400">ğŸ” ë””ë²„ê·¸ ì •ë³´</h3>
            <div className="space-y-1 text-xs text-gray-300">
              <div>
                <span className="text-gray-500">í™˜ê²½:</span> {debugInfo.isMobile ? 'ğŸ“± ëª¨ë°”ì¼' : 'ğŸ’» ë°ìŠ¤í¬í†±'}
              </div>
              <div>
                <span className="text-gray-500">STT ëª¨ë“œ:</span>
                <span className={debugInfo.useServerSTT ? 'text-blue-400' : 'text-green-400'}>
                  {debugInfo.useServerSTT ? ' ğŸ”„ ì„œë²„ STT' : ' ğŸ—£ï¸ Web Speech API'}
                </span>
              </div>
              <div>
                <span className="text-gray-500">Speech API:</span>
                <span className={debugInfo.speechSupport ? 'text-green-400' : 'text-red-400'}>
                  {debugInfo.speechSupport ? ' âœ… ì§€ì›ë¨' : ' âŒ ì§€ì›ë˜ì§€ ì•ŠìŒ'}
                </span>
              </div>
              <div>
                <span className="text-gray-500">MediaDevices:</span>
                <span className={debugInfo.mediaDevicesSupport ? 'text-green-400' : 'text-red-400'}>
                  {debugInfo.mediaDevicesSupport ? ' âœ… ì§€ì›ë¨' : ' âŒ ì§€ì›ë˜ì§€ ì•ŠìŒ'}
                </span>
              </div>
              <div className="text-gray-500 text-xs truncate">
                ë¸Œë¼ìš°ì €: {debugInfo.userAgent.split(' ').slice(-2).join(' ')}
              </div>
              {debugInfo.useServerSTT && (
                <div className="text-xs text-blue-300 mt-2 p-2 bg-blue-900/20 rounded">
                  ğŸ“± ë…¹ìŒ ì¢…ë£Œ í›„ ì „ì²´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì„œë²„ë¡œ ì „ì†¡í•˜ì—¬ í…ìŠ¤íŠ¸ ë³€í™˜
                </div>
              )}
            </div>
          </div>
        )}

        {/* Recording Button */}
        <div className="flex justify-center mb-8">
          <button
            onClick={isRecording ? stopRecording : startRecording}
            className={`w-32 h-32 rounded-full border-4 transition-all duration-200 ${
              isRecording
                ? 'bg-red-600 border-red-400 animate-pulse'
                : 'bg-blue-600 border-blue-400 hover:bg-blue-700'
            }`}
          >
            <div className="flex flex-col items-center">
              <div className="text-4xl mb-2">ğŸ¤</div>
              <div className="text-sm font-semibold">
                {isRecording ? 'ì¤‘ì§€' : 'ë…¹ìŒ'}
              </div>
            </div>
          </button>
        </div>

        {/* Current Recording Status */}
        {isRecording && (
          <div className="bg-gray-800 rounded-lg p-4 mb-6">
            <h3 className="text-lg font-semibold mb-2 text-red-400">ğŸ”´ ë…¹ìŒ ì¤‘...</h3>
            <div className="bg-gray-900 rounded p-3 min-h-[80px]">
              <p className="text-gray-300">
                {currentTranscript || 'ìŒì„±ì„ ì¸ì‹í•˜ê³  ìˆìŠµë‹ˆë‹¤...'}
              </p>
            </div>
          </div>
        )}

        {/* Saved Memos */}
        <div className="space-y-4">
          <h2 className="text-xl font-semibold mb-4">
            ì €ì¥ëœ ë©”ëª¨ ({memos.length})
          </h2>

          {isLoadingMemos ? (
            <div className="space-y-4">
              {[...Array(3)].map((_, i) => (
                <div key={i} className="bg-gray-800 rounded-lg p-4">
                  <div className="animate-pulse">
                    <div className="h-4 bg-gray-700 rounded w-1/4 mb-2"></div>
                    <div className="h-3 bg-gray-700 rounded w-full mb-1"></div>
                    <div className="h-3 bg-gray-700 rounded w-3/4"></div>
                  </div>
                </div>
              ))}
            </div>
          ) : memos.length === 0 ? (
            <div className="text-center py-12 text-gray-500">
              <div className="text-6xl mb-4">ğŸ“</div>
              <p>ì•„ì§ ì €ì¥ëœ ë©”ëª¨ê°€ ì—†ìŠµë‹ˆë‹¤.</p>
              <p className="text-sm">ìœ„ì˜ ë…¹ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì²« ë²ˆì§¸ ë©”ëª¨ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”!</p>
            </div>
          ) : (
            memos.map((memo) => (
              <div key={memo.id} className="bg-gray-800 rounded-lg p-4 relative group">
                <button
                  onClick={() => deleteMemo(memo.id)}
                  className="absolute top-2 right-2 w-8 h-8 bg-red-600 text-white rounded-full opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex items-center justify-center text-sm"
                  title="ë©”ëª¨ ì‚­ì œ"
                >
                  âœ•
                </button>
                <div className="flex items-start gap-3">
                  <div className="text-blue-400 mt-1">ğŸ“</div>
                  <div className="flex-1 pr-8">
                    <div className="text-xs text-gray-500 mb-1">
                      ë©”ëª¨ #{memo.id} â€¢ {new Date(memo.created_at).toLocaleString('ko-KR')}
                    </div>
                    <p className="text-white leading-relaxed">{memo.content}</p>
                  </div>
                </div>
              </div>
            ))
          )}
        </div>
      </div>
    </div>
  );
}