'use client';

/* eslint-disable @typescript-eslint/no-explicit-any */

import { useState, useRef, useEffect } from 'react';
import Header from '@/components/Header';
import { getUserId, getShortUserId } from '@/utils/userUtils';

interface MemoData {
  id: number;
  user_id: string;
  content: string;
  created_at: string;
  updated_at: string;
}

type RecordingStatus = 'idle' | 'recording' | 'processing' | 'completed';

export default function VoiceMemoPage() {
  const [recordingStatus, setRecordingStatus] = useState<RecordingStatus>('idle');
  const [memos, setMemos] = useState<MemoData[]>([]);
  const [currentTranscript, setCurrentTranscript] = useState('');
  const [isLoadingMemos, setIsLoadingMemos] = useState(true);
  const [userId, setUserId] = useState<string>('');
  const [debugInfo, setDebugInfo] = useState<{
    userAgent: string;
    speechSupport: boolean;
    mediaDevicesSupport: boolean;
    isMobile: boolean;
    useServerSTT: boolean;
  } | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recognitionRef = useRef<unknown>(null);
  const audioChunksRef = useRef<BlobPart[]>([]);
  const chunkTimerRef = useRef<NodeJS.Timeout | null>(null);

  // ë©”ëª¨ ëª©ë¡ ì¡°íšŒ í•¨ìˆ˜
  const fetchMemos = async (userIdParam: string) => {
    try {
      const response = await fetch(`/api/memo?userId=${encodeURIComponent(userIdParam)}`);
      const result = await response.json();

      if (result.success) {
        setMemos(result.data);
      } else {
        console.error('Failed to fetch memos:', result.message);
      }
    } catch (error) {
      console.error('Error fetching memos:', error);
    } finally {
      setIsLoadingMemos(false);
    }
  };

  // ë©”ëª¨ ì €ì¥ í•¨ìˆ˜
  const saveMemo = async (content: string) => {
    if (!userId || !content.trim()) return;

    try {
      const response = await fetch('/api/memo', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          userId: userId,
          content: content.trim()
        }),
      });

      const result = await response.json();

      if (result.success) {
        console.log('ë©”ëª¨ ì €ì¥ ì„±ê³µ:', result.data);
        // ë©”ëª¨ ëª©ë¡ ìƒˆë¡œê³ ì¹¨
        await fetchMemos(userId);
      } else {
        console.error('Failed to save memo:', result.message);
      }
    } catch (error) {
      console.error('Error saving memo:', error);
    }
  };

  // ë©”ëª¨ ì‚­ì œ í•¨ìˆ˜
  const deleteMemo = async (memoId: number) => {
    if (!userId) return;

    try {
      const response = await fetch(`/api/memo?id=${memoId}&userId=${encodeURIComponent(userId)}`, {
        method: 'DELETE',
      });

      const result = await response.json();

      if (result.success) {
        console.log('ë©”ëª¨ ì‚­ì œ ì„±ê³µ');
        // ë©”ëª¨ ëª©ë¡ ìƒˆë¡œê³ ì¹¨
        await fetchMemos(userId);
      } else {
        console.error('Failed to delete memo:', result.message);
      }
    } catch (error) {
      console.error('Error deleting memo:', error);
    }
  };

  // Initialize user ID and fetch data on component mount
  useEffect(() => {
    // ì‚¬ìš©ì ID ì´ˆê¸°í™”
    const initUserId = getUserId();
    setUserId(initUserId);
    console.log('ì‚¬ìš©ì ID ì´ˆê¸°í™”:', initUserId);

    // ë””ë²„ê·¸ ì •ë³´ ì„¤ì •
    const isMobile = /Android|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
    const speechSupport = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
    const mediaDevicesSupport = 'mediaDevices' in navigator && 'getUserMedia' in navigator.mediaDevices;

    // ëª¨ë°”ì¼ í™˜ê²½ì—ì„œëŠ” ì„œë²„ STT ì‚¬ìš©, ë°ìŠ¤í¬í†±ì—ì„œëŠ” Web Speech API ì‚¬ìš©
    const useServerSTT = isMobile || !speechSupport;

    setDebugInfo({
      userAgent: navigator.userAgent,
      speechSupport,
      mediaDevicesSupport,
      isMobile,
      useServerSTT
    });

    console.log('ğŸ” ë””ë²„ê·¸ ì •ë³´:', {
      isMobile,
      speechSupport,
      mediaDevicesSupport,
      userAgent: navigator.userAgent
    });

    // ë©”ëª¨ ëª©ë¡ ì¡°íšŒ
    fetchMemos(initUserId);
  }, []);

  // Google Speech APIë¡œ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¸ì‹
  const uploadAudioChunk = async (audioBlob: Blob) => {
    try {
      console.log('ğŸ“¤ ì˜¤ë””ì˜¤ ì²­í¬ ì—…ë¡œë“œ ì‹œì‘:', { size: audioBlob.size, type: audioBlob.type });

      const formData = new FormData();
      formData.append('audio', audioBlob, `chunk.${audioBlob.type.includes('webm') ? 'webm' : 'mp4'}`);

      const response = await fetch('/api/stt', {
        method: 'POST',
        body: formData
      });

      if (!response.ok) {
        throw new Error(`STT API ì˜¤ë¥˜: ${response.statusText}`);
      }

      const result = await response.json();
      console.log('ğŸ“ STT ê²°ê³¼ ìˆ˜ì‹ :', result);

      if (result.text) {
        setCurrentTranscript(result.text.trim());
        console.log('ğŸ“„ í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ:', result.text.trim());

        // ì¦‰ì‹œ ì €ì¥ ì²˜ë¦¬
        console.log('ğŸ’¾ ë©”ëª¨ ìë™ ì €ì¥ ì‹œì‘...');
        await saveMemo(result.text.trim());
        console.log('âœ… ë©”ëª¨ ì €ì¥ ì™„ë£Œ');

        // ì™„ë£Œ ìƒíƒœë¡œ ë³€ê²½
        setRecordingStatus('completed');

        // 2ì´ˆ í›„ ì´ˆê¸° ìƒíƒœë¡œ ë³µêµ¬
        setTimeout(() => {
          setRecordingStatus('idle');
          setCurrentTranscript('');
        }, 2000);
      }

    } catch (error) {
      console.error('âŒ STT ì—…ë¡œë“œ ì˜¤ë¥˜:', error);
      setRecordingStatus('idle'); // ì˜¤ë¥˜ ì‹œ ì´ˆê¸° ìƒíƒœë¡œ ë³µêµ¬
    }
  };

  const startRecording = async () => {
    try {
      console.log('ğŸ¤ ìŒì„± ë…¹ìŒ ì‹œì‘ ì‹œë„...');

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      console.log('âœ… ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íšë“ ì„±ê³µ');

      // MediaRecorder mimeType í˜¸í™˜ì„± ì²˜ë¦¬
      let mimeType = 'audio/webm;codecs=opus';
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'audio/webm';
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = 'audio/mp4'; // iOS Safari ëŒ€ë¹„
        }
      }
      console.log('ğŸ“¼ ì‚¬ìš©í•  MIME íƒ€ì…:', mimeType);

      const mediaRecorder = new MediaRecorder(stream, { mimeType });
      mediaRecorderRef.current = mediaRecorder;

      // ì˜¤ë””ì˜¤ ì²­í¬ ì´ˆê¸°í™”
      audioChunksRef.current = [];

      // MediaRecorder ì´ë²¤íŠ¸ ì„¤ì •
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          console.log('ğŸ“¦ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì§‘:', event.data.size, 'bytes');
        }
      };

      const isMobile = /Android|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
      const speechSupport = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
      const useServerSTT = isMobile || !speechSupport;

      // ëª¨ë“  í™˜ê²½ì—ì„œ Google Speech API ì‚¬ìš©
      console.log('ğŸ¤ Google Speech API ì‚¬ìš© ëª¨ë“œ');

      // MediaRecorder ì‹œì‘ (1ì´ˆ ê°„ê²©ìœ¼ë¡œ dataavailable ì´ë²¤íŠ¸ ë°œìƒ)
      mediaRecorder.start(1000);
      setRecordingStatus('recording');
      setCurrentTranscript('');
      console.log('âœ… ë…¹ìŒ ì‹œì‘ ì™„ë£¼ - Google Speech API ëª¨ë“œ');

    } catch (error) {
      console.error('âŒ ë…¹ìŒ ì‹œì‘ ì¤‘ ì˜¤ë¥˜:', error);
      alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  };

  const stopRecording = async () => {
    console.log('ğŸ›‘ ìŒì„± ë…¹ìŒ ì¤‘ì§€ ì‹œì‘...');

    // MediaRecorder ì¤‘ì§€
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      console.log('âœ… MediaRecorder ì¤‘ì§€ ì™„ë£Œ');
    }

    // ì²˜ë¦¬ ì¤‘ ìƒíƒœë¡œ ë³€ê²½
    setRecordingStatus('processing');

    // ë…¹ìŒëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ Google Speech APIë¡œ ì²˜ë¦¬
    if (audioChunksRef.current.length > 0) {
      console.log('ğŸ“¤ ë…¹ìŒ ì™„ë£Œ - Google Speech APIë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ ì‹œì‘...');

      const chunks = audioChunksRef.current.splice(0);
      const mimeType = mediaRecorderRef.current?.mimeType || 'audio/webm';
      const audioBlob = new Blob(chunks, { type: mimeType });

      console.log('ğŸ“¤ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´:', {
        size: audioBlob.size,
        type: audioBlob.type
      });

      if (audioBlob.size > 0) {
        try {
          // Google Speech APIë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ ìš”ì²­ (ì—¬ê¸°ì„œ ìë™ ì €ì¥ë„ ì²˜ë¦¬ë¨)
          await uploadAudioChunk(audioBlob);
        } catch (error) {
          console.error('âŒ í…ìŠ¤íŠ¸ ë³€í™˜ ì˜¤ë¥˜:', error);
          setRecordingStatus('idle'); // ì˜¤ë¥˜ ì‹œ ì´ˆê¸° ìƒíƒœë¡œ ë³µêµ¬
        }
      } else {
        setRecordingStatus('idle'); // ë…¹ìŒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì´ˆê¸° ìƒíƒœë¡œ
      }
    } else {
      setRecordingStatus('idle'); // ë…¹ìŒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì´ˆê¸° ìƒíƒœë¡œ
    }
  };

  return (
    <div className="min-h-screen bg-gray-950 text-white">
      <Header title="Voice Memo" />

      <div className="pt-20 px-4 max-w-4xl mx-auto">
        <div className="text-center mb-8">
          <h1 className="text-3xl font-bold mb-4">ìŒì„± ë©”ëª¨</h1>
          <p className="text-gray-400">ë²„íŠ¼ì„ ëˆŒëŸ¬ ìŒì„±ì„ ë…¹ìŒí•˜ê³  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì„¸ìš”</p>

          {/* User ID Display */}
          {userId && (
            <div className="mt-4 inline-flex items-center gap-2 px-3 py-1 bg-gray-800 rounded-full">
              <div className="w-2 h-2 bg-green-500 rounded-full"></div>
              <span className="text-xs text-gray-300">
                ì‚¬ìš©ì ID: {getShortUserId(userId)}
              </span>
            </div>
          )}
        </div>


        {/* Recording Button */}
        <div className="flex justify-center mb-8">
          <button
            onClick={recordingStatus === 'recording' ? stopRecording : startRecording}
            disabled={recordingStatus === 'processing' || recordingStatus === 'completed'}
            className={`w-32 h-32 rounded-full border-4 transition-all duration-200 ${
              recordingStatus === 'recording'
                ? 'bg-red-600 border-red-400 animate-pulse'
                : recordingStatus === 'processing'
                ? 'bg-yellow-600 border-yellow-400 animate-spin'
                : recordingStatus === 'completed'
                ? 'bg-green-600 border-green-400'
                : 'bg-blue-600 border-blue-400 hover:bg-blue-700'
            } ${(recordingStatus === 'processing' || recordingStatus === 'completed') ? 'cursor-not-allowed' : 'cursor-pointer'}`}
          >
            <div className="flex flex-col items-center">
              <div className="text-4xl mb-2">
                {recordingStatus === 'recording' ? 'ğŸ¤' :
                 recordingStatus === 'processing' ? 'â³' :
                 recordingStatus === 'completed' ? 'âœ…' : 'ğŸ¤'}
              </div>
              <div className="text-sm font-semibold">
                {recordingStatus === 'recording' ? 'ë…¹ìŒ ì¤‘...' :
                 recordingStatus === 'processing' ? 'ì²˜ë¦¬ ì¤‘...' :
                 recordingStatus === 'completed' ? 'ì™„ë£Œ!' : 'ë…¹ìŒ ì‹œì‘'}
              </div>
            </div>
          </button>
        </div>


      </div>
    </div>
  );
}