import { NextRequest, NextResponse } from 'next/server';

export const runtime = 'nodejs';

export async function POST(req: NextRequest) {
  try {
    const form = await req.formData();
    const file = form.get('audio') as File | null;

    if (!file) {
      return NextResponse.json({
        error: 'audio file missing'
      }, { status: 400 });
    }

    console.log('ğŸ¤ STT ìš”ì²­ ìˆ˜ì‹ :', {
      name: file.name,
      type: file.type,
      size: file.size
    });

    const buffer = Buffer.from(await file.arrayBuffer());
    const mime = file.type;

    // TODO: ì‹¤ì œ STT ì—”ì§„ ì—°ê²° (Whisper, OpenAI, Deepgram ë“±)
    // í˜„ì¬ëŠ” ë°ëª¨ìš© ì‘ë‹µ
    const text = await mockSTTProcessing(buffer, mime);

    console.log('ğŸ“ STT ê²°ê³¼:', text);

    return NextResponse.json({
      text,
      partial: true // ë¶€ë¶„ ê²°ê³¼ì„ì„ í‘œì‹œ
    });

  } catch (error) {
    console.error('âŒ STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', error);

    return NextResponse.json({
      error: 'STT processing failed',
      details: error instanceof Error ? error.message : 'Unknown error'
    }, { status: 500 });
  }
}

// ì„ì‹œ STT ì²˜ë¦¬ í•¨ìˆ˜ (ì‹¤ì œ STT ì—”ì§„ìœ¼ë¡œ êµì²´ ì˜ˆì •)
async function mockSTTProcessing(buffer: Buffer, _mimeType: string): Promise<string> {
  // ì˜¤ë””ì˜¤ í¬ê¸°ì— ë”°ë¥¸ ëª¨ì˜ í…ìŠ¤íŠ¸ ìƒì„±
  const sizeKB = buffer.length / 1024;

  const mockTexts = [
    'ì•ˆë…•í•˜ì„¸ìš”',
    'ìŒì„± ì¸ì‹ì´ ì˜ ë˜ê³  ìˆìŠµë‹ˆë‹¤',
    'ì„œë²„ì—ì„œ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤',
    'ëª¨ë°”ì¼ì—ì„œë„ ì •ìƒ ë™ì‘í•©ë‹ˆë‹¤',
    'í…ìŠ¤íŠ¸ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤'
  ];

  // ì˜¤ë””ì˜¤ í¬ê¸°ì— ë”°ë¼ ë‹¤ë¥¸ ì‘ë‹µ (ì‹¤ì œë¡œëŠ” STT ê²°ê³¼)
  const index = Math.floor(sizeKB / 10) % mockTexts.length;

  // ì‹¤ì œ STT ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•œ ì§€ì—°
  await new Promise(resolve => setTimeout(resolve, 200));

  return mockTexts[index];
}

// ì‹¤ì œ OpenAI Whisper API ì‚¬ìš© ì˜ˆì‹œ (ì£¼ì„ ì²˜ë¦¬)
/*
async function processWithWhisper(buffer: Buffer, mimeType: string): Promise<string> {
  const formData = new FormData();

  // ì˜¤ë””ì˜¤ í˜•ì‹ì— ë”°ë¥¸ í™•ì¥ì ê²°ì •
  let extension = 'webm';
  if (mimeType.includes('mp4')) extension = 'mp4';
  else if (mimeType.includes('wav')) extension = 'wav';

  const audioBlob = new Blob([buffer], { type: mimeType });
  formData.append('file', audioBlob, `audio.${extension}`);
  formData.append('model', 'whisper-1');
  formData.append('language', 'ko');

  const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
    },
    body: formData,
  });

  if (!response.ok) {
    throw new Error(`Whisper API error: ${response.statusText}`);
  }

  const result = await response.json();
  return result.text || '';
}
*/